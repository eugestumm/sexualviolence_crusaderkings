{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using VADER to generate a sentiment analysis of the reddit posts, titles, and comments\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that we are already familiar with the data, we can start to analyze it. In this notebook, we will use the VADER (Valence Aware Dictionary and sEntiment Reasoner) library to analyze the sentiment of the reddit posts, titles, and comments. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is a good choice for this project because it is designed to analyze sentiments in social media posts, which is exactly what we are doing.\n",
    "\n",
    "## Importing the Libraries\n",
    "\n",
    "We will start by importing the libraries that we will use in this notebook. We will use the csv file for manipulating the data and the vaderSentiment library for analyzing the sentiment of the reddit posts, titles, and comments.\n",
    "\n",
    "## Importing the Data\n",
    "\n",
    "We will start by importing the data that we cleaned in the previous Python Notebook.\n",
    "\n",
    "## Analyzing the Sentiment of the Reddit posts, titles, and comments \n",
    "\n",
    "We will start by analyzing the sentiment of the reddit posts. We will use the vaderSentiment library to analyze the sentiment of the reddit posts. We will use the polarity_scores() function to analyze the sentiment of the reddit posts. The polarity_scores() function returns a dictionary of scores of the sentiment of the reddit posts, titles, and comments. This function will return a neg (negative), a neu (neutral), and a pos (positive) score. They represent the percentage of the post that correspond to each sentiment. The compound score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive). We will add the scores to the dataframe.\n",
    "\n",
    "After this process is done for each of the reddit posts, titles, and comments, we will save the dataframe to a csv file. One for the comments and other for the posts and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Define the file names\n",
    "posts_file = 'posts.csv'\n",
    "comments_file = 'comments.csv'\n",
    "posts_sentiment_file = 'posts_sentiment.csv'\n",
    "comments_sentiment_file = 'comments_sentiment.csv'\n",
    "\n",
    "# Create an instance of SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Open the input files and the output files\n",
    "with open(posts_file, 'r', newline='', encoding='utf-8') as f_posts, \\\n",
    "     open(comments_file, 'r', newline='', encoding='utf-8') as f_comments, \\\n",
    "     open(posts_sentiment_file, 'w', newline='', encoding='utf-8') as f_posts_sentiment, \\\n",
    "     open(comments_sentiment_file, 'w', newline='', encoding='utf-8') as f_comments_sentiment:\n",
    "\n",
    "    # Create the CSV reader and writer objects\n",
    "    posts_reader = csv.reader(f_posts)\n",
    "    comments_reader = csv.reader(f_comments)\n",
    "    posts_sentiment_writer = csv.writer(f_posts_sentiment)\n",
    "    comments_sentiment_writer = csv.writer(f_comments_sentiment)\n",
    "\n",
    "    # Write the header row for the output files\n",
    "    posts_sentiment_writer.writerow(['post_id', 'title', 'body', 'score', 'ups', 'downs', 'title_compound', 'title_pos', 'title_neu', 'title_neg', 'body_compound', 'body_pos', 'body_neu', 'body_neg'])\n",
    "    comments_sentiment_writer.writerow(['post_id', 'comment_id', 'comment', 'score', 'ups', 'downs', 'compound', 'pos', 'neu', 'neg'])\n",
    "\n",
    "    # Skip the header row of the input files\n",
    "    next(posts_reader)\n",
    "    next(comments_reader)\n",
    "\n",
    "    # Loop over the posts and analyze their sentiment\n",
    "    for post_row in posts_reader:\n",
    "        post_id, title, body, score, ups, downs = post_row\n",
    "        title_scores = analyzer.polarity_scores(title)\n",
    "        title_compound = title_scores['compound']\n",
    "        title_pos = title_scores['pos']\n",
    "        title_neu = title_scores['neu']\n",
    "        title_neg = title_scores['neg']\n",
    "        body_scores = analyzer.polarity_scores(body)\n",
    "        body_compound = body_scores['compound']\n",
    "        body_pos = body_scores['pos']\n",
    "        body_neu = body_scores['neu']\n",
    "        body_neg = body_scores['neg']\n",
    "        posts_sentiment_writer.writerow([post_id, title, body, score, ups, downs, title_compound, title_pos, title_neu, title_neg, body_compound, body_pos, body_neu, body_neg])\n",
    "\n",
    "    # Loop over the comments and analyze their sentiment\n",
    "    for comment_row in comments_reader:\n",
    "        post_id, comment_id, comment, score, ups, downs = comment_row\n",
    "        scores = analyzer.polarity_scores(comment)\n",
    "        compound = scores['compound']\n",
    "        pos = scores['pos']\n",
    "        neu = scores['neu']\n",
    "        neg = scores['neg']\n",
    "        comments_sentiment_writer.writerow([post_id, comment_id, comment, score, ups, downs, compound, pos, neu, neg])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b50a28a276beed389a39c662b4f3a82d56c4623de1da336b4f5eb55d32abec6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
